{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67403492",
   "metadata": {},
   "source": [
    "Laboratory 2: Computer Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5678ab1d",
   "metadata": {},
   "source": [
    "Part 1: MNIST Digit Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1237c37",
   "metadata": {},
   "source": [
    "In the first portion of this lab, we will build and train a Convolution Neural Network (CNN) for classification of handwritten digits from the famous MNIST dataset. The MNIST dataset consist of 60,000 training images and 10,000 test images. Our classes are the digits 0-9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6238f21b",
   "metadata": {},
   "source": [
    "First, let's download the course repository, install dependencies, and import the relevant packages we'll need for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ec9fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch and other relevant libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchsummary import summary\n",
    "\n",
    "# Other packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b77cb2ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Please enable GPU",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m COMET_API_KEY = \u001b[33m\"\u001b[39m\u001b[33mIfAOqB1pulTvZR0qAUE9qFPjW\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Check that we are using a GPU\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m torch.cuda.is_available(), \u001b[33m\"\u001b[39m\u001b[33mPlease enable GPU\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m COMET_API_KEY != \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mPlease insert your Comet API Key\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Set GPU for computation\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: Please enable GPU"
     ]
    }
   ],
   "source": [
    "import comet_ml\n",
    "# TODO: ENTER YOUR API KEY HERE !!\n",
    "COMET_API_KEY = \"IfAOqB1pulTvZR0qAUE9qFPjW\"\n",
    "\n",
    "# Check that we are using a GPU\n",
    "assert torch.cuda.is_available(), \"Please enable GPU\"\n",
    "assert COMET_API_KEY != \"\", \"Please insert your Comet API Key\"\n",
    "\n",
    "# Set GPU for computation\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available () else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb7dd641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m comet_ml.init() is deprecated and will be removed soon. Please use comet_ml.login()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please paste your Comet API key from https://www.comet.com/api/my/settings/\n",
      "(api key may not show as you type)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in C:\\Users\\anthonny.paz\\.comet.config (set COMET_CONFIG to change where it is saved).\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/anthonny20/deep-learning-lab2-part2-nn/caf04f4a6b3b4005b78f95134ddb5e35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Failed to log system metrics: [sys.ram,sys.cpu,sys.load]\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Failed to log system metrics: [sys.ram,sys.cpu,sys.load]\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m Failed to log system metrics: [sys.ram,sys.cpu,sys.load]\n"
     ]
    }
   ],
   "source": [
    "# start a first comet experiment for the first part of the lab\n",
    "comet_ml.init(project_name=\"Deep_Learning_lab2_part2_NN\")\n",
    "comet_model_1 = comet_ml.Experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5b2091",
   "metadata": {},
   "source": [
    "MNIST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fc406c",
   "metadata": {},
   "source": [
    "Let's download and load the dataset and display a few random samples from it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8734da0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and transform the MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "        # Convert images to PyTorch tensors which also scales data from [0, 255] to [0,1]\n",
    "        transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Download training and test datasets\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7a6479",
   "metadata": {},
   "source": [
    "The MNIST dataset object in PyTorch is not a simple tensor or array. It's an iterable dataset that loads samples (image-label pairs) one at a time or in batches. In a later section of this lab, we will define a handy DataLoader to process the data in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88f6fec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "image, label = train_dataset[0]\n",
    "print(image.size()) # For a tensor: torch.Size([1, 28, 28])\n",
    "print(label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learn-3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
