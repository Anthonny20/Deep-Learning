{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127d106a",
   "metadata": {},
   "source": [
    "Part 2: Musig Generation with RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d93fa3",
   "metadata": {},
   "source": [
    "In this position of the lab, we will explore building a Recurrent Neural Network (RNN) for music generation using PyTorch. We will train a model to learn the patterns in raw sheet musin in ABC notation and then use this model to generate new music."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9059a73",
   "metadata": {},
   "source": [
    "2.1 Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156cee4a",
   "metadata": {},
   "source": [
    "First, let's download the course repository, install dependencies, and import the relevant packages we'll need for this lab.\n",
    "\n",
    "We will be using Comet ML to track our model development and training runs. First, sign up for a Comet account at this link[https://www.comet.com/signup?utm_source=mit_dl&utm_medium=partner&utm_content=github].You will need to generate a new API Key, which you can find either in the first 'Get Started with Comet' page, under your account settings, or by pressing the '?' in the top right corner and the 'Quickstart Guide'. Enter this API Key as the global variable COMET_API_KEY."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0d50418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anthonny\\Documents\\GitHub\\Deep-Learning\\mit-env-3-10\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import comet_ml\n",
    "# TODO: ENTER YOUR API KEY HERE! \n",
    "COMET_API_KEY = \"IfAOqB1pulTvZR0qAUE9qFPjW\"\n",
    "\n",
    "# Import PyTorch and other relevant libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import mitdeeplearning as mdl\n",
    "\n",
    "# Import all remaining packages\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import functools\n",
    "from IPython import display as ipythondisplay\n",
    "from tqdm import tqdm\n",
    "from scipy.io.wavfile import write\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "549b18f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA disponível: True\n",
      "Nome da GPU: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n",
      "Versão CUDA: 12.1\n",
      "Versão PyTorch: 2.5.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA disponível:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Nome da GPU:\", torch.cuda.get_device_name(0))\n",
    "    print(\"Versão CUDA:\", torch.version.cuda)\n",
    "    print(\"Versão PyTorch:\", torch.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f640e2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Please enable GPU from runtime settings",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check that we are using a GPU, if not switch runtimes\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#   using Runtime > Change Runtime Type > GPU\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease enable GPU from runtime settings\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m COMET_API_KEY \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease insert your Comet API key\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Please enable GPU from runtime settings"
     ]
    }
   ],
   "source": [
    "# Check that we are using a GPU, if not switch runtimes\n",
    "#   using Runtime > Change Runtime Type > GPU\n",
    "assert torch.cuda.is_available(), \"Please enable GPU from runtime settings\"\n",
    "assert COMET_API_KEY != \"\", \"Please insert your Comet API key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ed98ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU disponível? False\n",
      "Nome da GPU: Nenhuma GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"GPU disponível?\", torch.cuda.is_available())\n",
    "print(\"Nome da GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"Nenhuma GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed32623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mit-env-3-10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
