{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eec1c786",
   "metadata": {},
   "source": [
    "Lab 1: Intro to Pytorch and Music Generation with RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e0212e",
   "metadata": {},
   "source": [
    "In this lab, you'll get exposure to using PyTorch and learn how it can be used for deep learning. Go through the code and run each cell.\n",
    "Along the way, you'll encouter several TODO blocks -- follow the instructions to fill them out before running those cells and continuing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e2b4af",
   "metadata": {},
   "source": [
    "Part1: Intro to PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580710f5",
   "metadata": {},
   "source": [
    "Pytorch is a popular deep learning library known for its flexibility and ease of use. Here we'll learn how computations are represented and how to define a simple neural network in PyTorch. For all the labs in Introduction to Deep Learning 2025, there will be a Pytorch version available.\n",
    "\n",
    "Let's install PyTorch and a couple of dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "800dfd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import mitdeeplearning as mdl\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3044f76a",
   "metadata": {},
   "source": [
    "1.1 What is PyTorch?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dabde5",
   "metadata": {},
   "source": [
    "Pytorch is a machine learning library, like TensorFlow. At it's core, PyTorch provides an interface for creating and manipulating tensors, which are data structures that you can think of as multi-dimensional arrays. Tensors are represented as n-dimensional arrays of base datatypes such as a string or integer -- they provide a way to generalize vectors and matrices to higher dimensions. PyTorch provides the ability to perform computation on these tensors, define neural networks, and train them efficiently.\n",
    "\n",
    "The shape of a PyTorch tensor defines its number of dimensions and the size of each dimension. The ndim or dim of a Pytorch tensor provides the number of dimensions (n-dimensions) --  this is equivalent to the tensor's rank(as is used in TensorFlow), and you can also think of this as the tensor's order or degree.\n",
    "\n",
    "Let's start by changing some tensors and inspecting their properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ef58d228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Integer` is a 0-d Tensor: 1234\n",
      "`Decimal` is a 0-d Tensor: 3.1415927410125732\n"
     ]
    }
   ],
   "source": [
    "integer = torch.tensor(1234)\n",
    "decimal = torch.tensor(3.14159265359)\n",
    "\n",
    "print(f\"`Integer` is a {integer.ndim}-d Tensor: {integer}\")\n",
    "print(f\"`Decimal` is a {decimal.ndim}-d Tensor: {decimal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5936e56",
   "metadata": {},
   "source": [
    "Vectors and lists can be used to create 1-d tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d09ba4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Fibonacci` is a 1-d Tensor with shape: torch.Size([6])\n",
      "`count_to_100` is a 1-d Tensor with shape: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "fibonacci = torch.tensor([1, 1, 2, 3, 5, 8])\n",
    "count_to_100 = torch.tensor(range(100))\n",
    "\n",
    "print(f\"`Fibonacci` is a {fibonacci.ndim}-d Tensor with shape: {fibonacci.shape}\")\n",
    "print(f\"`count_to_100` is a {count_to_100.ndim}-d Tensor with shape: {count_to_100.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d78828",
   "metadata": {},
   "source": [
    "Next, let's create 2-d (i.e., matrices) and higher-rank tensors. In image processing and Computer Vision, we will use 4-d Tensors with dimensions corresponding to batch size, number of color channels, image height, and image width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "697b488c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images is a 4-d Tensor with shape: torch.Size([10, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "### Defining higher-order Tensors ###\n",
    "'''TODO: Define a 2-d Tensor'''\n",
    "matrix = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "assert isinstance(matrix, torch.Tensor), \"matrix must be a torch Tensor object\"\n",
    "assert matrix.ndim == 2\n",
    "\n",
    "'''TODO: Define a 4-d Tensor'''\n",
    "# Use torch.zeros to initialize a 4-d Tensor of zeros with size 10 x 3 x 256 x 256.\n",
    "#   You can think of this as 10 images where each image is RGB 256 X 256.\n",
    "images = torch.zeros(10, 3, 256, 256)\n",
    "\n",
    "assert isinstance(images, torch.Tensor), \"images must be a torch Tensor object\"\n",
    "assert images.ndim == 4, \"images must have 4 dimensions\"\n",
    "assert images.shape == (10, 3, 256, 256), \"images is incorrect shape\"\n",
    "print(f\"images is a {images.ndim}-d Tensor with shape: {images.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc9fa8a",
   "metadata": {},
   "source": [
    "As you have seen, the shape of a tensor provides the number of elements in each tensor dimension. The shape is quite useful, and we'll use it often. You can also use slicing to access subtensors within a higher-rank tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c25a0db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row_vector: tensor([4, 5, 6])\n",
      "column_vector: tensor([2, 5])\n",
      "scalar: 2\n"
     ]
    }
   ],
   "source": [
    "row_vector = matrix[1]\n",
    "column_vector = matrix[:,1]\n",
    "scalar = matrix[0, 1]\n",
    "\n",
    "print(f\"row_vector: {row_vector}\")\n",
    "print(f\"column_vector: {column_vector}\")\n",
    "print(f\"scalar: {scalar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef5709b",
   "metadata": {},
   "source": [
    "Computations on Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c392a7c",
   "metadata": {},
   "source": [
    "A convenient way to think about and visualize computations in a machine learning framework like PyTorch is in terms of graphs. We can define this graph in terms of tensors, which hold data, and the mathematical operations that act on these tensors im some order. Let's look at a simple example, and define this computation using PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ce4fd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1: 76\n",
      "c2: 76\n"
     ]
    }
   ],
   "source": [
    "# Create the nodes in the graph and initialize values\n",
    "a = torch.tensor(15)\n",
    "b = torch.tensor(61)\n",
    "\n",
    "# Add them!\n",
    "c1 = torch.add(a, b)\n",
    "c2 = a + b # PyTorch overrides the \"+\" operation so that it is able to act on Tensors\n",
    "print(f\"c1: {c1}\")\n",
    "print(f\"c2: {c2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3455542b",
   "metadata": {},
   "source": [
    "Notice how we've created a computation graph consisting of PyTorch operations, and how the output is a tensor with value 76 -- we've just created a computation graph consisting of operations, and it's executed them and given us back the result.\n",
    "\n",
    "Now let's consider a slightly more complicated example:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cafbf9",
   "metadata": {},
   "source": [
    "Here, we take two inputs, a, b, and compute an output e. Each node in the graph represents an operation that takes some input, does some computation, and passes its output to another node.\n",
    "\n",
    "Let's define a simple function in PyTorch to construct this computation function:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 7,
=======
   "execution_count": 35,
>>>>>>> 80ad75b1b7b7f03e7a81d74d007bdc93be89a057
   "id": "f06440cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining Tensor computations ###\n",
    "# Construct a simple computation function\n",
    "def func(a, b):\n",
    "    '''TODO: Define the operation for c, d, e'''\n",
    "    c = torch.tensor(a) + torch.tensor(b)\n",
    "    d = torch.tensor(b) - torch.tensor(1)\n",
    "    e = torch.tensor(c) * torch.tensor(d)\n",
    "    return torch.tensor(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8f7a0e",
   "metadata": {},
   "source": [
    "Now, we can call this function to execute the computaion graph given some inputs a, b:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 36,
>>>>>>> 80ad75b1b7b7f03e7a81d74d007bdc93be89a057
   "id": "4aa4ff5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e_out: 6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "C:\\Users\\anthonny.paz\\AppData\\Local\\Temp\\ipykernel_16332\\3275148877.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  e = torch.tensor(c) * torch.tensor(d)\n",
      "C:\\Users\\anthonny.paz\\AppData\\Local\\Temp\\ipykernel_16332\\3275148877.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
=======
      "C:\\Users\\anthonny.paz\\AppData\\Local\\Temp\\ipykernel_2460\\3275148877.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  e = torch.tensor(c) * torch.tensor(d)\n",
      "C:\\Users\\anthonny.paz\\AppData\\Local\\Temp\\ipykernel_2460\\3275148877.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
>>>>>>> 80ad75b1b7b7f03e7a81d74d007bdc93be89a057
      "  return torch.tensor(e)\n"
     ]
    }
   ],
   "source": [
    "# Consider example values for a, b\n",
    "a, b = 1.5, 2.5\n",
    "# Execute the computation\n",
    "e_out = func(a, b)\n",
    "print(f\"e_out: {e_out}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf2449f",
   "metadata": {},
   "source": [
    "Notice how our output is a tensor with valu defined by the output of the computation, and that the output has no shape as it is a single scalar value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6b99fa",
   "metadata": {},
   "source": [
    "1.3 Neural Networks in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d987e170",
   "metadata": {},
   "source": [
    "We can also define neural networks in PyTorch. PyTorch uses torch.nn.Module, which serves as a base class for all neural network modules in PyTorch and thus provides a framework for building and training neural networks.\n",
    "\n",
    "Let's consider the example of a simple perceptron defined by just one dense (aka fully-connected or linear) layer: y = (sigma)(Wx + b), where W represents a matrix of weights, b is a bias, x is the input, sigma os the sigmoid activation function, and y is the output.\n",
    "\n",
    "We will use torch.nn.Module to define layers -- the building blocks of neural networks. Layers implement common neural networks operations. In PyTorch, when we implement a layer, we subclass nn.Module and define the parameters of the layer as attributes of our new class. We also define and override a function forward, which will define the forward pass computation that is performed at every step. All classes subclassing nn.Module should override the forward function.\n",
    "\n",
    "Let's write a dense layer class to implement a perceptron defined above."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 37,
>>>>>>> 80ad75b1b7b7f03e7a81d74d007bdc93be89a057
   "id": "4dca6f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining a dense layer###\n",
    "\n",
    "# num_inputs: number of input nodes\n",
    "# num_outputs: number of output nodes\n",
    "# x: input to the layer\n",
    "\n",
    "class OurDenseLayer(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super(OurDenseLayer, self).__init__()\n",
    "        # Define and initialize parameters: a weight matrix W and bias b\n",
    "        # Note that the parameter initialize is random!\n",
    "        self.W = torch.nn.Parameter(torch.randn(num_inputs, num_outputs))\n",
    "        self.bias = torch.nn.Parameter(torch.randn(num_outputs))\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''TODO: define the operation for z (hint: use torch.matmul).'''\n",
    "        z = torch.matmul(x, self.W) + self.bias\n",
    "\n",
    "        '''TODO: define the operation for out (hint: use torch.sigmoid)'''\n",
    "        y = torch.sigmoid(z)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec0f4ce",
   "metadata": {},
   "source": [
    "Now, let's test the output of our layer."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 38,
>>>>>>> 80ad75b1b7b7f03e7a81d74d007bdc93be89a057
   "id": "c4d1b24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([1, 2])\n",
      "output shape: torch.Size([1, 3])\n",
<<<<<<< HEAD
      "output result: tensor([[0.9773, 0.7110, 0.6721]], grad_fn=<SigmoidBackward0>)\n"
=======
      "output result: tensor([[0.4648, 0.0183, 0.0626]], grad_fn=<SigmoidBackward0>)\n"
>>>>>>> 80ad75b1b7b7f03e7a81d74d007bdc93be89a057
     ]
    }
   ],
   "source": [
    "# Define a layer and test the output!\n",
    "\n",
    "num_inputs = 2\n",
    "num_outputs = 3\n",
    "layer = OurDenseLayer(num_inputs, num_outputs)\n",
    "x_input = torch.tensor([[1, 2.]])\n",
    "y = layer(x_input)\n",
    "\n",
    "print(f\"input shape: {x_input.shape}\")\n",
    "print(f\"output shape: {y.shape}\")\n",
    "print(f\"output result: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004a7b30",
   "metadata": {},
   "source": [
    "Conveniently, PyTorch has defined a number of nn.Modules (or Layers) that are commomly used in Neural Networks, for example a nn.Linear or nn.Sigmoid module.\n",
    "\n",
    "Now, instead of using a single Module to define our simple Neural Network, we'll use the nn.Sequential module from PyTorch and a single nn.Linear layer to define our network. With the Sequential API, you can readily create neural networks by stacking together layers like building blocks."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 39,
>>>>>>> 80ad75b1b7b7f03e7a81d74d007bdc93be89a057
   "id": "51e917f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining a Neural Network using PyTorch Sequential API ###\n",
    "\n",
    "# define the number of inputs and outputs\n",
    "n_input_nodes = 2\n",
    "n_output_nodes = 3\n",
    "\n",
    "# Define the model\n",
    "'''TODO: Use the Sequental API to define a neural network with a single linear (dense!) layer, followed by non-linearity to compute z'''\n",
    "# model = nn.Sequential( ''' TODO ''' )\n",
    "model = nn.Sequential(\n",
    "    # linear layer with input size 2 and output size 3\n",
    "    nn.Linear(n_input_nodes, n_output_nodes),\n",
    "    # Sigmoid activation function\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64592d24",
   "metadata": {},
   "source": [
    "We've defined our model using the Sequential API. Now, we can test it out using an exampe input:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 40,
>>>>>>> 80ad75b1b7b7f03e7a81d74d007bdc93be89a057
   "id": "f58a5cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([1, 2])\n",
      "output shape: torch.Size([1, 3])\n",
<<<<<<< HEAD
      "output result: tensor([[0.9773, 0.7110, 0.6721]], grad_fn=<SigmoidBackward0>)\n"
=======
      "output result: tensor([[0.4648, 0.0183, 0.0626]], grad_fn=<SigmoidBackward0>)\n"
>>>>>>> 80ad75b1b7b7f03e7a81d74d007bdc93be89a057
     ]
    }
   ],
   "source": [
    "# Test the model with example input\n",
    "x_input = torch.tensor([[1, 2.]])\n",
    "model_output = model(x_input)\n",
    "print(f\"input shape: {x_input.shape}\")\n",
    "print(f\"output shape: {y.shape}\")\n",
    "print(f\"output result: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286df76a",
   "metadata": {},
   "source": [
    "With PyTorch, we can create more flexible models by subclassing nn.Module. The nn.Module class allows us to group layers together flexibly to define new architectures.\n",
    "\n",
    "As we saw earlier with OurDenseLayer, we can subclass nn.Module to create a class for our model, and then define the forward pass through the network using the forward function. Subclassing affords the flexibility to define custom layers, custom training loops, custom activation functions, and custom models. Let's define the same neural network model as above (i.e., Linear layer with an activation funciton after it), now using subclassing and using PyTorch's built in linear layer from nn.Linear."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 43,
>>>>>>> 80ad75b1b7b7f03e7a81d74d007bdc93be89a057
   "id": "be251208",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining a model using subclassing ###\n",
    "\n",
    "class LinearWithSigmoidActivation(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super(LinearWithSigmoidActivation, self).__init__()\n",
    "        '''TODO: define a model with a single Linear layer and sigmoid activation'''\n",
    "        self.linear = nn.Linear(num_inputs, num_outputs)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        linear_output = self.linear(inputs)\n",
    "        output = self.activation(linear_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c32fb5",
   "metadata": {},
   "source": [
    "Let's test out our new model, using an exampe input, setting n_input_nodes=2 and n_output_nodes=3 as before."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 51,
>>>>>>> 80ad75b1b7b7f03e7a81d74d007bdc93be89a057
   "id": "eeaf44f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: torch.Size([1, 2])\n",
      "output shape: torch.Size([1, 3])\n",
<<<<<<< HEAD
      "output results: tensor([[0.7646, 0.8844, 0.6385]], grad_fn=<SigmoidBackward0>)\n"
=======
      "output results: tensor([[0.6801, 0.7621, 0.2525]], grad_fn=<SigmoidBackward0>)\n"
>>>>>>> 80ad75b1b7b7f03e7a81d74d007bdc93be89a057
     ]
    }
   ],
   "source": [
    "n_input_nodes = 2\n",
    "n_output_nodes = 3\n",
    "model = LinearWithSigmoidActivation(n_input_nodes, n_output_nodes)\n",
    "x_input = torch.tensor([[1, 2.]])\n",
    "y = model(x_input)\n",
    "print(f\"input shape: {x_input.shape}\")\n",
    "print(f\"output shape: {y.shape}\")\n",
    "print(f\"output results: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4020e75f",
   "metadata": {},
   "source": [
    "Importantly, nn.Module affords us a lot of flexibility to define custom models. For example, we can use boolean arguments in the forward function to specify different network behaviors, for example different behaviors during training and inference. Let's suppose under some instances we want our network to simply output the input, without any pertubation. We define a boolean argument isidentity to control this behavior:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": null,
>>>>>>> 80ad75b1b7b7f03e7a81d74d007bdc93be89a057
   "id": "b379b4bd",
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "### Custom behavior with subclassing nn.Module ###\n",
    "class LinearButSometimesIdentity(nn.Module):\n",
    "    def __init__(self, num_inputs, num_outputs):\n",
    "        super(LinearButSometimesIdentity, self).__init__()\n",
    "        self.linear = nn.Linear(num_inputs, num_outputs)\n",
    "\n",
    "        '''TODO: Implement the behavior where the netowrk outputs the input, unchanged, under control of the isidentity argument'''\n",
    "\n",
    "    def forward(self, inputs, isidentity=False):\n",
    "        '''TODO'''\n",
    "        if isidentity:\n",
    "            return inputs\n",
    "        else:\n",
    "            return self.linear(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dc214f",
   "metadata": {},
   "source": [
    "Let's test this behavior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "135f1fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([[1., 2.]])\n",
      "Network linear output: tensor([[ 0.9479, -0.0402,  0.7981]], grad_fn=<AddmmBackward0>); network identity output: tensor([[1., 2.]])\n"
     ]
    }
   ],
   "source": [
    "#Test the IndetityModel\n",
    "model = LinearButSometimesIdentity(num_inputs=2, num_outputs=3)\n",
    "x_input = torch.tensor([[1, 2.]])\n",
    "\n",
    "'''TODO: pass the input into the model and call with and without the input identity option'''\n",
    "out_with_linear = model(x_input)\n",
    "\n",
    "out_with_identity = model(x_input, isidentity=True)\n",
    "\n",
    "print(f\"input: {x_input}\")\n",
    "print(\"Network linear output: {}; network identity output: {}\".format(out_with_linear, out_with_identity))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3028b93a",
   "metadata": {},
   "source": [
    "Now that we have learned how to define layers and models in PyTorch using both the Sequential API and subclassing nn.Module, we're ready to turn our attetion to how to actually implement network training with backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c88fb93",
   "metadata": {},
   "source": [
    "1.4 Automatic Differentiation in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e18257a",
   "metadata": {},
   "source": [
    "In PyTorch, torch.autograd is used for automatic differatiation, which is critical for training deep learning models with backpropagation.\n",
    "\n",
    "We will use the PyTorch .backward() method to trace operations for computing gradients. On a tensor, the requires_grad attribute controls whether autograd should record operations on that tensor. When a forward pass is made through the network, PyTorch builds a computational graph dynamically; then, to compute the gradient, the backward() method is called to perform backpropagation.\n",
    "\n",
    "Let's compute the gradiend of y = x^2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a03c0f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dy_dx of y=x^2 at x=3.0 is tensor(6.)\n",
      "tensor(9., grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "### Gradient Computation ###\n",
    "\n",
    "# y = x^2\n",
    "# Example: x = 3.0\n",
    "\n",
    "x = torch.tensor(3.0, requires_grad=True)\n",
    "y = x ** 2\n",
    "y.backward() # Compute the gradient\n",
    "\n",
    "dy_dx = x.grad\n",
    "print(\"dy_dx of y=x^2 at x=3.0 is\", dy_dx)\n",
    "assert dy_dx == 6.0\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf1a207",
   "metadata": {},
   "source": [
    "In training neural networks, we use differentiation and stochastic gradient descent (SGD) to optmize a loss function. Now that we have a sense of how PyTorch's autograd can be used to compute and access derivates, we will look at an example where we use automatic differentiation and SGD to find the minimum of L=(x - xf)^2. Here xf is a variable for a desired value we are trying to optimize for; L represents a loss that we are trying to minimize. While we can clearly solve this problem analytically (xmin = xf), considering how we can compute this using PyTorch's autograd sets us up nicely for future labs where we use gradient descent to optimize entire neural network losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d13a1650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing x=-0.554279088973999\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Function minimization with autograd and gradient descent ###\n",
    "\n",
    "# Initialize a random value for our initial x\n",
    "x = torch.randn(1)\n",
    "print(f\"Initializing x={x.item()}\")\n",
    "\n",
    "learning_rate = 1e-2 # Learning Rate\n",
    "history = []\n",
    "x_f = 4 # Target Value\n",
    "\n",
    "# We will run gradient descent for a number of iterations. At each iteration, we compute the loss, \n",
    "#  compute the derivate of the loss with respect to x, and perform the update.\n",
    "for i in range(500):\n",
    "    x = torch.tensor([x], requires_grad=True)\n",
    "\n",
    "    # TODO: Compute the loss as the square of the difference between x and x_f\n",
    "    loss = torch.pow((x - x_f), 2)\n",
    "\n",
    "    # Backpropagation through the loss to compute gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # Update x with gradient descent\n",
    "    x= x.item() - learning_rate * x.grad\n",
    "\n",
    "    history.append(x.item())\n",
    "\n",
    "# Plot the evolution of x as we optimize toward x_f!\n",
    "plt.plot(history)\n",
    "plt.plot([0, 500], [x_f, x_f])\n",
    "plt.legend(('Predicted', 'True'))\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel(\"x value\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7997c737",
   "metadata": {},
   "source": [
    "Now, we have covered the fundamental concepts of PyTorch--tensors, operations, neural networks, and automatic differentiation."
=======
    "()"
>>>>>>> 80ad75b1b7b7f03e7a81d74d007bdc93be89a057
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learn-3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
